{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.0-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.1 kB ? eta -:--:--\n",
      "     ------------------------------------- -- 41.0/44.1 kB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 44.1/44.1 kB 721.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\raidb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\raidb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\raidb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\raidb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.9.11-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.5/41.5 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\raidb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\raidb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\raidb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\raidb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\raidb\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\raidb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raidb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raidb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raidb\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Downloading transformers-4.46.0-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/10.0 MB 2.6 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.2/10.0 MB 2.5 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.4/10.0 MB 2.7 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.5/10.0 MB 3.0 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.7/10.0 MB 2.8 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.8/10.0 MB 2.9 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/10.0 MB 3.0 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.1/10.0 MB 3.0 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 3.0 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.5/10.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.6/10.0 MB 3.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.8/10.0 MB 3.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.9/10.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.0/10.0 MB 3.2 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.2/10.0 MB 3.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.2/10.0 MB 2.9 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.4/10.0 MB 3.0 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.7/10.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.8/10.0 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.1/10.0 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.3/10.0 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.5/10.0 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.7/10.0 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.0/10.0 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.5/10.0 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.5/10.0 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.7/10.0 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.9/10.0 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.1/10.0 MB 3.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.4/10.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.7/10.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.4/10.0 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.7/10.0 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.0/10.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.5/10.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.8/10.0 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.2/10.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.1/10.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.5/10.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 4.9 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.26.1-py3-none-any.whl (447 kB)\n",
      "   ---------------------------------------- 0.0/447.4 kB ? eta -:--:--\n",
      "   --------------------------------- ----- 389.1/447.4 kB 12.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 389.1/447.4 kB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 447.4/447.4 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading regex-2024.9.11-cp312-cp312-win_amd64.whl (273 kB)\n",
      "   ---------------------------------------- 0.0/273.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 273.5/273.5 kB 8.2 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.3 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 256.0/286.3 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 256.0/286.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 286.3/286.3 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.20.1-cp312-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.4/2.4 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.8/2.4 MB 8.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.1/2.4 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.4/2.4 MB 8.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.4 MB 7.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.0/2.4 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 6.9 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.26.1 regex-2024.9.11 safetensors-0.4.5 tokenizers-0.20.1 transformers-4.46.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=500):\n",
    "\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids, \n",
    "            max_length=max_length, \n",
    "            num_return_sequences=1,  \n",
    "            temperature=0.7,         \n",
    "            top_k=50,                \n",
    "            top_p=0.9,               \n",
    "            do_sample=True           \n",
    "        )\n",
    "\n",
    "\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: Hello, it's my first time working with the new language!\n",
      "\n",
      "The first thing I did was to create a new language for my company, and I found that it was not very easy to learn. I wanted to learn from the people I was working with, and I wanted to make sure that I was learning the language.\n",
      "\n",
      "The first thing I did was to create a new language for my company, and I found that it was not very easy to learn. I wanted to learn from the people I was working with, and I wanted to make sure that I was learning the language. The first thing I did was to create a new language for my company, and I found that it was not very easy to learn. I wanted to learn from the people I was working with, and I wanted to make sure that I was learning the language. I have a few more questions about the language, but I am going to get to them in a moment.\n",
      "\n",
      "I have a few more questions about the language, but I am going to get to them in a moment. The first thing I did was to create a new language for my company, and I found that it was not very easy to learn. I wanted to learn from the people I was working with, and I wanted to make sure that I was learning the language. I am also going to be writing a book on the language.\n",
      "\n",
      "I am also going to be writing a book on the language. The first thing I did was to create a new language for my company, and I found that it was not very easy to learn. I wanted to learn from the people I was working with, and I wanted to make sure that I was learning the language. I am also going to be writing a book on the language. I have a few more questions about the language, but I am going to get to them in a moment.\n",
      "\n",
      "The first thing I did was to create a new language for my company, and I found that it was not very easy to learn. I wanted to learn from the people I was working with, and I wanted to make sure that I was learning the language. I have a few more questions about the language, but I am going to get to them in a moment.\n",
      "\n",
      "The first thing I did was to create a new language for my company, and I found that it was not very easy to learn. I wanted to learn from the people I was\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Hello\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(\"Generated Text:\", generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
